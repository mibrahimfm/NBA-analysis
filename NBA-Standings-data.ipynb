{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-e917ee99ac47>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mipynb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfull\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mUtilCollections\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mTEAM_TO_ABBR\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mipynb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfull\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mUtilFunctions\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mformat_season\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Documents\\University\\UFMG\\2021-2\\Monografia\\NBA_Data\\UtilFunctions.ipynb\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m    \u001b[1;34m\"cell_type\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m\"code\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m    \u001b[1;34m\"execution_count\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m    \u001b[1;34m\"metadata\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m    \u001b[1;34m\"outputs\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m    \"source\": [\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\scipy\\stats\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    382\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdivision\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprint_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mabsolute_import\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    383\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 384\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mstats\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    385\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mdistributions\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    386\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mmorestats\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\scipy\\stats\\stats.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    183\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mspecial\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mspecial\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlinalg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 185\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdistributions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    186\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmstats_basic\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m from ._stats_mstats_common import (_find_repeats, linregress, theilslopes,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\scipy\\stats\\distributions.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m                                     rv_frozen)\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_continuous_distns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_discrete_distns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\scipy\\stats\\_continuous_distns.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m   4750\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4751\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4752\u001b[1;33m \u001b[0mloggamma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloggamma_gen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'loggamma'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4753\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4754\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\scipy\\stats\\_distn_infrastructure.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, momtype, a, b, xtol, badvalue, name, longname, shapes, extradoc, seed)\u001b[0m\n\u001b[0;32m   1633\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1634\u001b[0m                 \u001b[0mdct\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdistcont\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1635\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_construct_doc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdocdict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdct\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1636\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1637\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_updated_ctor_param\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\scipy\\stats\\_distn_infrastructure.py\u001b[0m in \u001b[0;36m_construct_doc\u001b[1;34m(self, docdict, shapes_vals)\u001b[0m\n\u001b[0;32m    730\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"%(shapes)s, \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    731\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 732\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdoccer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdocformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtempdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    733\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    734\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Unable to construct docstring for distribution \\\"%s\\\": %s\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrepr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\scipy\\_lib\\doccer.py\u001b[0m in \u001b[0;36mdocformat\u001b[1;34m(docstring, docdict)\u001b[0m\n\u001b[0;32m     53\u001b[0m         \u001b[0micount\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m         \u001b[0micount\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindentcount_lines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlines\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     56\u001b[0m     \u001b[0mindent\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m' '\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0micount\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[1;31m# Insert this indent to dictionary docstrings\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\scipy\\_lib\\doccer.py\u001b[0m in \u001b[0;36mindentcount_lines\u001b[1;34m(lines)\u001b[0m\n\u001b[0;32m    196\u001b[0m         \u001b[0mstripped\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    197\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mstripped\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 198\u001b[1;33m             \u001b[0mindentno\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindentno\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstripped\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    199\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mindentno\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmaxsize\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "from ipynb.fs.full.UtilCollections import TEAM_TO_ABBR\n",
    "from ipynb.fs.full.UtilFunctions import format_season\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_standings_from_espn(season):\n",
    "    first_year, second_year = format_season(season)\n",
    "    url = \"https://www.espn.com/nba/standings/_/season/{}\".format(season)\n",
    "    \n",
    "    html = urlopen(url)\n",
    "    soup = BeautifulSoup(html)\n",
    "    \n",
    "    tables = soup.findAll('table')\n",
    "    eastern_teams = pd.read_html(str(tables[0]))[0]\n",
    "    eastern_teams.loc[-1] = eastern_teams.columns[0]\n",
    "    eastern_teams.index = eastern_teams.index + 2  # shifting index\n",
    "    eastern_teams.sort_index(inplace=True)\n",
    "    eastern_teams.rename(columns={eastern_teams.columns[0]:'Team'}, inplace=True)\n",
    "    eastern_stats = pd.read_html(str(tables[1]))[0]\n",
    "    eastern_stats.index = eastern_stats.index + 1\n",
    "    western_teams = pd.read_html(str(tables[2]))[0]\n",
    "    western_teams.loc[-1] = western_teams.columns[0]\n",
    "    western_teams.index = western_teams.index + 2  # shifting index\n",
    "    western_teams.sort_index(inplace=True) \n",
    "    western_teams.rename(columns={western_teams.columns[0]:'Team'}, inplace=True)\n",
    "    western_stats = pd.read_html(str(tables[3]))[0]\n",
    "    western_stats.index = western_stats.index + 1\n",
    "    \n",
    "    eastern_standings = pd.concat([eastern_teams, eastern_stats], axis=1)\n",
    "    eastern_standings[\"Made_Playoffs\"] = False\n",
    "    western_standings = pd.concat([western_teams, western_stats], axis=1)\n",
    "    western_standings[\"Made_Playoffs\"] = False\n",
    "    \n",
    "    for team in eastern_standings[\"Team\"]:\n",
    "        if team[1] in ['x', 'y', 'z', '*']: #Chars that start the row and indicate the team made the playoffs\n",
    "            eastern_standings.loc[eastern_standings[\"Team\"] == team, [\"Made_Playoffs\"]] = True\n",
    "            \n",
    "        if '--' in team:\n",
    "            adjusted_team_name = team.split('--')[1]\n",
    "        else:\n",
    "            adjusted_team_name = team\n",
    "\n",
    "        while not (adjusted_team_name[1]>= 'a' and adjusted_team_name[1] <= 'z'): #Make sure the column only has team names\n",
    "            adjusted_team_name = adjusted_team_name[1:]\n",
    "            \n",
    "        eastern_standings.loc[eastern_standings[\"Team\"] == team, [\"Team\"]] = adjusted_team_name.upper()\n",
    "\n",
    "    for team in western_standings[\"Team\"]:\n",
    "        if team[1] in ['x', 'y', 'z', '*']: #Chars that start the row and indicate the team made the playoffs\n",
    "            western_standings.loc[western_standings[\"Team\"] == team, [\"Made_Playoffs\"]] = True                \n",
    "        \n",
    "        if '--' in team:\n",
    "            adjusted_team_name = team.split('--')[1]\n",
    "        else:\n",
    "            adjusted_team_name = team\n",
    "            \n",
    "        if \"Clippers\" in adjusted_team_name:\n",
    "            adjusted_team_name = \"Los Angeles Clippers\"\n",
    "            \n",
    "        while not (adjusted_team_name[1]>= 'a' and adjusted_team_name[1] <= 'z'): #Make sure the column only has team names\n",
    "            adjusted_team_name = adjusted_team_name[1:]\n",
    "        \n",
    "        adjusted_team_name = adjusted_team_name.replace('  ', ' ')\n",
    "        \n",
    "        western_standings.loc[western_standings[\"Team\"] == team, [\"Team\"]] = adjusted_team_name.upper()\n",
    "        \n",
    "    eastern_standings[\"Team\"] = eastern_standings['Team'].apply(lambda x: TEAM_TO_ABBR[x])\n",
    "    western_standings[\"Team\"] = western_standings['Team'].apply(lambda x: TEAM_TO_ABBR[x])\n",
    "\n",
    "            \n",
    "    return eastern_standings, western_standings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_playoff_series(season):\n",
    "    selector = \"div_all_playoffs\"\n",
    "    url = f'https://widgets.sports-reference.com/wg.fcgi?css=1&site=bbr&url=%2Fleagues%2FNBA_{season}.html&div={selector}'\n",
    "    html = urlopen(url)\n",
    "    soup = BeautifulSoup(html)\n",
    "    table = soup.find('table')\n",
    "    df = pd.read_html(str(table))[0]\n",
    "    \n",
    "    df.drop([2, 3, 4, 5], axis='columns', inplace=True)\n",
    "    \n",
    "    df.rename(columns={0 : 'Series', 1: \"Winner_over_loser\"}, inplace=True)\n",
    "    \n",
    "    for row, col in df.iterrows():\n",
    "        if \"Game\" in str(col[0]):\n",
    "            df.drop(row, inplace=True)\n",
    "            \n",
    "    df.dropna(how='all', inplace=True)\n",
    "            \n",
    "    winners, losers_and_results = [wl.split(\" over \")[0] for wl in df[\"Winner_over_loser\"]], [wl.split(\" over \")[1] for wl in df[\"Winner_over_loser\"]]\n",
    "    losers, results = [lr.split(\"(\")[0] for lr in losers_and_results], [lr.split(\"(\")[1] for lr in losers_and_results]\n",
    "    wins, losses = [int(wl.split(\"-\")[0]) for wl in results], [int(wl.split(\"-\")[1][0]) for wl in results]\n",
    "    \n",
    "    winners = [TEAM_TO_ABBR[w.strip().upper()] for w in winners]\n",
    "    losers = [TEAM_TO_ABBR[l.strip().upper()] for l in losers]\n",
    "\n",
    "    \n",
    "    df[\"Winner\"] = winners\n",
    "    df[\"Loser\"] = losers\n",
    "    df[\"Winner_total_wins\"] = wins\n",
    "    df[\"Loser_total_wins\"] = losses\n",
    "    \n",
    "    df.drop(\"Winner_over_loser\", axis='columns', inplace=True)\n",
    "\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_standings(eastern_standings, western_standings):\n",
    "    standings = pd.concat([western_standings, eastern_standings])\n",
    "    standings.sort_values(by=[\"Made_Playoffs\", \"W\", \"Rank\", \"Team\"], ascending=[False, False, True, True], inplace=True)\n",
    "    standings.reset_index(inplace=True)\n",
    "    standings.drop('index', axis=1, inplace=True)\n",
    "    standings.index += 1\n",
    "    standings[\"Rank\"] = standings.index\n",
    "    return standings[[\"Team\", \"Rank\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_playoff_standings(season):\n",
    "    playoffs = get_playoff_series(season)\n",
    "    first_year, second_year = format_season(season)\n",
    "    western_standings = pd.read_csv(\"DataCollection/Standings/standings_western_conference_{0}-{1}.csv\".format(first_year, second_year))\n",
    "    eastern_standings = pd.read_csv(\"DataCollection/Standings/standings_eastern_conference_{0}-{1}.csv\".format(first_year, second_year))\n",
    "    standings = merge_standings(eastern_standings, western_standings)\n",
    "    \n",
    "    teams = []\n",
    "    \n",
    "    winners = pd.DataFrame(playoffs.groupby(by='Winner').sum())\n",
    "    \n",
    "    #add champion and finalist\n",
    "    finals = playoffs[playoffs[\"Series\"] == \"Finals\"]\n",
    "    champion = finals[\"Winner\"][0]\n",
    "    finalist = finals[\"Loser\"][0]\n",
    "    \n",
    "    champion_wins = winners.loc[champion]['Winner_total_wins']\n",
    "    champion_losses = winners.loc[champion]['Loser_total_wins']\n",
    "    finalist_wins = winners.loc[finalist]['Winner_total_wins'] + finals[\"Loser_total_wins\"][0]\n",
    "    finalist_losses = winners.loc[finalist]['Loser_total_wins'] + finals[\"Winner_total_wins\"][0]\n",
    "    \n",
    "    teams.append((champion, champion_wins, champion_losses))\n",
    "    teams.append((finalist, finalist_wins, finalist_losses))\n",
    "    \n",
    "    #add conference finalists\n",
    "    \n",
    "    western_conf_finals = playoffs[playoffs[\"Series\"] == \"Western Conference Finals\"]\n",
    "    western_conf_finals.reset_index(drop=True, inplace=True)\n",
    "    eastern_conf_finals = playoffs[playoffs[\"Series\"] == \"Eastern Conference Finals\"]\n",
    "    eastern_conf_finals.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    west_finalist = western_conf_finals['Loser'][0]\n",
    "    east_finalist = eastern_conf_finals['Loser'][0]\n",
    "    \n",
    "    west_finalist_wins = winners.loc[west_finalist][\"Winner_total_wins\"] + western_conf_finals[\"Loser_total_wins\"][0]\n",
    "    west_finalist_losses = winners.loc[west_finalist][\"Loser_total_wins\"] + western_conf_finals[\"Winner_total_wins\"][0]\n",
    "    east_finalist_wins = winners.loc[east_finalist][\"Winner_total_wins\"] + eastern_conf_finals[\"Loser_total_wins\"][0]    \n",
    "    east_finalist_losses = winners.loc[east_finalist][\"Loser_total_wins\"] + eastern_conf_finals[\"Winner_total_wins\"][0]\n",
    "\n",
    "    teams.append((west_finalist, west_finalist_wins, west_finalist_losses))\n",
    "    teams.append((east_finalist, east_finalist_wins, east_finalist_losses))\n",
    "    \n",
    "    #add conference semifinalists\n",
    "    \n",
    "    western_conf_semifinals = playoffs[playoffs[\"Series\"] == \"Western Conference Semifinals\"]\n",
    "    eastern_conf_semifinals = playoffs[playoffs[\"Series\"] == \"Eastern Conference Semifinals\"]\n",
    "    \n",
    "    for team in western_conf_semifinals['Loser']:\n",
    "        semifinals = western_conf_semifinals[western_conf_semifinals['Loser'] == team]\n",
    "        semifinals.reset_index(drop=True, inplace=True)\n",
    "        team_wins = winners.loc[team][\"Winner_total_wins\"] + semifinals['Loser_total_wins'][0]\n",
    "        team_losses = winners.loc[team][\"Loser_total_wins\"] + semifinals['Winner_total_wins'][0]\n",
    "        teams.append((team, team_wins, team_losses))\n",
    "        \n",
    "    for team in eastern_conf_semifinals['Loser']:\n",
    "        semifinals = eastern_conf_semifinals[eastern_conf_semifinals['Loser'] == team]\n",
    "        semifinals.reset_index(drop=True, inplace=True)\n",
    "        team_wins = winners.loc[team][\"Winner_total_wins\"] + semifinals['Loser_total_wins'][0]\n",
    "        team_losses = winners.loc[team][\"Loser_total_wins\"] + semifinals['Winner_total_wins'][0]\n",
    "        teams.append((team, team_wins, team_losses))\n",
    "        \n",
    "    western_conf_first_round = playoffs[playoffs[\"Series\"] == \"Western Conference First Round\"]\n",
    "    eastern_conf_first_round = playoffs[playoffs[\"Series\"] == \"Eastern Conference First Round\"]\n",
    "    \n",
    "    for team in western_conf_first_round['Loser']:\n",
    "        first_round = western_conf_first_round[western_conf_first_round['Loser'] == team]\n",
    "        first_round.reset_index(drop=True, inplace=True)\n",
    "        team_wins = first_round['Loser_total_wins'][0]\n",
    "        team_losses = first_round['Winner_total_wins'][0]\n",
    "        teams.append((team, team_wins, team_losses))\n",
    "        \n",
    "    for team in eastern_conf_first_round['Loser']:\n",
    "        first_round = eastern_conf_first_round[eastern_conf_first_round['Loser'] == team]\n",
    "        first_round.reset_index(drop=True, inplace=True)\n",
    "        team_wins = first_round['Loser_total_wins'][0]\n",
    "        team_losses = first_round['Winner_total_wins'][0]\n",
    "        teams.append((team, team_wins, team_losses))\n",
    "        \n",
    "    \n",
    "    df = pd.DataFrame(teams, columns=[\"Team\", \"Playoff_wins\", \"Playoff_losses\"])\n",
    "    playoff_standings = pd.merge(df, standings, how='inner', on='Team')\n",
    "    \n",
    "    playoff_standings.sort_values(by=[\"Playoff_wins\", \"Playoff_losses\", \"Rank\"], ascending=[False, True, True], inplace=True)\n",
    "\n",
    "    playoff_standings.to_csv(\"DataCollection/Standings_Playoffs/playoff_standings_{0}-{1}.csv\".format(first_year, second_year), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standings_to_csv(seasons, expanded=False):\n",
    "    for season in seasons:\n",
    "        eastern, western = get_standings_from_espn(season)\n",
    "        \n",
    "        first_year, second_year = format_season(season)\n",
    "        \n",
    "        csv_file_name_eastern = \"\"\n",
    "        csv_file_name_western = \"\"\n",
    "#         if expanded:\n",
    "#             csv_file_name = \"Standings/standings_{0}-{1}.csv\".format(first_year, second_year)\n",
    "#         else:\n",
    "        csv_file_name_eastern = \"DataCollection/Standings/standings_eastern_conference_{0}-{1}.csv\".format(first_year, second_year)\n",
    "        csv_file_name_western = \"DataCollection/Standings/standings_western_conference_{0}-{1}.csv\".format(first_year, second_year)    \n",
    "        \n",
    "        eastern.to_csv(csv_file_name_eastern, index=True, index_label=\"Rank\")\n",
    "        western.to_csv(csv_file_name_western, index=True, index_label=\"Rank\")       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seasons = range(2003,2023)\n",
    "\n",
    "standings_to_csv(seasons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
