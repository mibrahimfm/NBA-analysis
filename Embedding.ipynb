{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e8423dd-fdb7-46c7-aecb-1b4859759044",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from collections import OrderedDict\n",
    "from ipynb.fs.full.UtilFunctions import format_season\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e57ee8de-c655-4ca7-8a43-116e5d91d4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "position_to_number = {\n",
    "    \"PG\": 0,\n",
    "    \"SG\": 1,\n",
    "    \"SF\": 2,\n",
    "    \"PF\": 3,\n",
    "    \"C\": 4\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7642fb0-96d7-4cdc-8ef6-b5583d071cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process(seasons):\n",
    "    df = None\n",
    "    for season in seasons:\n",
    "        cols_to_drop = None\n",
    "        cols_to_keep = ['Player', 'Pos', 'Tm', 'TRB%', 'AST%', 'DRB%', 'ORB%', 'BLK%', '3PAr', '3PA', 'TOV%', 'STL%', 'PF', 'FGA', 'DBPM', '3P%', 'PTS', 'FTr']\n",
    "        first_year, second_year = format_season(season)\n",
    "        player_data = pd.read_csv(f\"DataCollection/Player_Stats/player_stats_{first_year}-{second_year}.csv\")\n",
    "        if season > 1997:\n",
    "            cols_to_drop = ['index', 'TRB', 'DRB', 'ORB', 'AST', 'G', 'GS', '2PAr', 'FT', 'FG', 'FG%', 'BLK', 'STL', 'Dunks', \n",
    "                                  'Heaves', 'HeavesAttempted', 'WS', 'FTA', 'TOV', 'Age', '2P', '3P', 'VORP', 'FGA', '3PA', '2PA', 'PF', 'PTS', 'OWS', 'DWS', 'OBPM', 'DBPM', 'BPM']\n",
    "            shooting_data = pd.read_csv(f\"DataCollection/Player_Shooting_Stats/Regular_Season/player_shooting_stats_{first_year}-{second_year}.csv\")\n",
    "            player_data = pd.merge(player_data, shooting_data.loc[:,~shooting_data.columns.isin(['Pos', 'Age', 'G', 'MP', 'FG%', \"3PAr\", \"2P%\", \"3P%\"])], on=['Player', 'Tm'])\n",
    "\n",
    "        else:\n",
    "            cols_to_drop = ['index', 'TRB', 'DRB', 'ORB', 'AST', 'G', 'GS', 'FT', 'FG', 'FG%', 'BLK', 'STL',\n",
    "                                'WS', 'FTA', 'TOV', 'Age', '2P', '3P', 'VORP', 'FGA', '3PA', '2PA', 'PF', 'PTS', 'OWS', 'DWS', 'OBPM', 'DBPM', 'BPM']\n",
    "            \n",
    "        player_data = player_data.fillna(0)\n",
    "        player_data = player_data[(player_data[\"MP\"] > 15) & (player_data[\"G\"] >= 30)]\n",
    "        player_data = player_data.sort_values(by=['G'], ascending=False)\n",
    "        player_data = player_data[player_data[\"Tm\"] != \"TOT\"]\n",
    "        player_data = player_data.drop_duplicates(subset =\"Player\",keep = \"first\")\n",
    "        player_data.reset_index(inplace=True)\n",
    "        player_data = player_data[cols_to_keep]        \n",
    "\n",
    "        if df is None:\n",
    "            df = player_data\n",
    "        else:\n",
    "            df = pd.concat([df, player_data])\n",
    "            \n",
    "    df.reset_index(inplace=True)\n",
    "    df.drop('index', axis=1, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e56671f-68ff-4f0a-a5d4-49de93035615",
   "metadata": {},
   "outputs": [],
   "source": [
    "#def train_test_split(seasons, training_seasons):\n",
    " #   train_df = pre_process(seasons[:-1], training_seasons)\n",
    "  #  test_df = pre_process(seasons[-1:], training_seasons)\n",
    "   # return train_df.loc[:, ~train_df.columns.isin(['Pos'])], test_df.loc[:, ~test_df.columns.isin(['Pos'])], train_df['Pos'], test_df['Pos']\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c1b4739-f68b-4af2-9619-afb87ff04879",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_by_year(seasons, training_seasons=4):\n",
    "    output_layers = []\n",
    "    accuracies = pd.DataFrame()\n",
    "    for season in seasons:\n",
    "        X_train, X_test, y_train, y_test = train_test_split(range(season,season+training_seasons+1), training_seasons)\n",
    "        y_train = [position_to_number[y] for y in y_train.values]\n",
    "        y_test = [position_to_number[y] for y in y_test.values]\n",
    "        X_train = torch.tensor(X_train.values, dtype=torch.float32)\n",
    "        X_test = torch.tensor(X_test.values, dtype=torch.float32)\n",
    "        y_train = torch.tensor(y_train, dtype=torch.long)\n",
    "        y_test = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "        n_samples, n_features = X_train.shape\n",
    "        model = nn.Sequential(OrderedDict([\n",
    "                ('dense1', nn.Linear(n_features, 21)),\n",
    "                ('act1', nn.ReLU()),\n",
    "                ('dense2', nn.Linear(21, 10)),\n",
    "                ('act1', nn.ReLU()),\n",
    "                ('output', nn.Linear(10, 5))\n",
    "            ]))\n",
    "\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "        loss_fn = nn.CrossEntropyLoss()\n",
    "        for epoch in range(iterations):\n",
    "            y_pred = model(X_train)\n",
    "            loss = loss_fn(y_pred, y_train)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            y_pred = model(X_test)\n",
    "            _, preds = torch.max(y_pred, 1)\n",
    "            accuracies[season+training_seasons] = accuracy_score(preds, y_test)\n",
    "            output_layers.append(model.output.weight) \n",
    "    return output_layers, accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "baab2376",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_train_test_split(seasons):\n",
    "    #Pre process data and select features/target\n",
    "    df = pre_process(seasons)\n",
    "    features = df.loc[:, ~df.columns.isin([\"Player\", \"Pos\", \"Tm\"])]\n",
    "    target = df['Pos']\n",
    "\n",
    "    #Split data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "    #Convert target to numbers\n",
    "    y_train = [position_to_number[y] for y in y_train.values]   \n",
    "    y_test = [position_to_number[y] for y in y_test.values]\n",
    "\n",
    "    #Convert data to tensors\n",
    "    X_train = torch.tensor(X_train.values, dtype=torch.float32)\n",
    "    X_test = torch.tensor(X_test.values, dtype=torch.float32)\n",
    "    y_train = torch.tensor(y_train, dtype=torch.long)\n",
    "    y_test = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "94a7c25e-770e-4ab0-a13c-5abd6ccb391e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = generate_train_test_split(range(2000,2023))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f1fa7e94-9257-42e3-b110-8ba470e8df29",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples, n_features = X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fdcbfecf-24d3-4f26-9d73-68d96fecdbac",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(OrderedDict([\n",
    "    ('dense1', nn.Linear(n_features, 512)),\n",
    "    ('act1', nn.ReLU()),\n",
    "    ('dense2', nn.Linear(512, 256)),\n",
    "    ('act2', nn.ReLU()),\n",
    "    ('dense3', nn.Linear(256, 128)),\n",
    "    ('act3', nn.ReLU()),\n",
    "    ('dense4', nn.Linear(128, 64)),\n",
    "    ('act4', nn.ReLU()),\n",
    "    ('dense5', nn.Linear(64, 32)),\n",
    "    ('act5', nn.ReLU()),\n",
    "    ('output', nn.Linear(32, 5))\n",
    "]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1344ca15-8923-4aef-b6d1-018c3bf20449",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2c00624c-4a9f-4de5-addc-5f98995d7bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aeaa48db-cc66-4c83-8adc-e08017df8162",
   "metadata": {},
   "outputs": [],
   "source": [
    "iterations = 1200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1e01b056-4fd6-4df8-b54a-b21cfabf5d47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, loss: 1.614\n",
      "epoch: 100, loss: 0.673\n",
      "epoch: 200, loss: 0.620\n",
      "epoch: 300, loss: 0.510\n",
      "epoch: 400, loss: 0.401\n",
      "epoch: 500, loss: 0.356\n",
      "epoch: 600, loss: 0.511\n",
      "epoch: 700, loss: 0.441\n",
      "epoch: 800, loss: 0.402\n",
      "epoch: 900, loss: 0.277\n",
      "epoch: 1000, loss: 0.119\n",
      "epoch: 1100, loss: 0.491\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(iterations):\n",
    "    y_pred = model(X_train)\n",
    "    loss = loss_fn(y_pred, y_train)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    if epoch % 100 == 0:\n",
    "        print(f\"epoch: {epoch}, loss: {loss.item():.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "532e1b6c-9b41-4311-9ab2-0c86a87ebc98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6333853354134166\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    y_pred = model(X_test)\n",
    "    _, preds = torch.max(y_pred, 1)\n",
    "    print(accuracy_score(preds, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9839e6df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_specialist = nn.Sequential(OrderedDict([\n",
    "    ('dense1', nn.Linear(n_features, 512)),\n",
    "    ('act1', nn.ReLU()),\n",
    "    ('dense2', nn.Linear(512, 256)),\n",
    "    ('act2', nn.ReLU()),\n",
    "    ('dense3', nn.Linear(256, 128)),\n",
    "    ('act3', nn.ReLU()),\n",
    "    ('dense4', nn.Linear(128, 64)),\n",
    "    ('act4', nn.ReLU()),\n",
    "    ('dense5', nn.Linear(64, 32)),\n",
    "    ('act5', nn.ReLU()),\n",
    "    ('output', nn.Linear(32, 5))\n",
    "]))\n",
    "\n",
    "model_specialist.load_state_dict(model.state_dict())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "496b5e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sp, X_test_sp, y_train_sp, y_test_sp = generate_train_test_split(range(2000, 2001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5354818e",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_sp = torch.optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "456840b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn_sp = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ca99aa7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "iterations_sp = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "395d68c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, loss: 0.542\n",
      "epoch: 100, loss: 0.542\n",
      "epoch: 200, loss: 0.542\n",
      "epoch: 300, loss: 0.542\n",
      "epoch: 400, loss: 0.542\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(iterations_sp):\n",
    "    y_pred_sp = model_specialist(X_train_sp)\n",
    "    loss = loss_fn(y_pred_sp, y_train_sp)\n",
    "    loss.backward()\n",
    "    optimizer_sp.step()\n",
    "    optimizer_sp.zero_grad()\n",
    "\n",
    "    if epoch % 100 == 0:\n",
    "        print(f\"epoch: {epoch}, loss: {loss.item():.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d4caf27f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7735849056603774\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    y_pred_sp = model(X_test_sp)\n",
    "    _, preds = torch.max(y_pred_sp, 1)\n",
    "    print(accuracy_score(preds, y_test_sp))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
